{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import pmdarima\n",
    "import arch\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import pmdarima\n",
    "import arch\n",
    "\n",
    "\n",
    "year = 2019\n",
    "ticker = 'IFM'\n",
    "string = str(year)+'/'+ticker+'.csv'\n",
    "col_names=['TIME', 'X', 'Y', 'Z'] \n",
    "\n",
    "df = pd.read_csv(os.path.join('E:\\CTA quant/ml_cta-master/data/index/',string), index_col=0, encoding='gbk')\n",
    "df.columns = ['code', 'time', 'open', 'high', 'low', 'close', 'volume', 'turnover', 'open interest']\n",
    "\n",
    "df.rename_axis(\"type\", axis='index', inplace=True)\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "#df = df.iloc[0:100, :]\n",
    "#df.head(1000)\n",
    "df['day'] = df['time'].map(lambda x: x.year)*10000 + df['time'].map(lambda x: x.month)*100 + df['time'].map(lambda x: x.day)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Get_indices(x):\n",
    "    \n",
    "    # return during the hold period\n",
    "\n",
    "    ret2 = sum(x.return_min)\n",
    "    vol = x.return_min.std(ddof = 0)\n",
    "    #vol = np.std(x.return_min.std)\n",
    "    \n",
    "    return pd.Series([vol,ret2], index=['Volatility','Logreturn2'])\n",
    "\n",
    "def get_best_model(df):\n",
    "    best_aic = np.inf \n",
    "    best_order = None\n",
    "    best_mdl = None\n",
    "    pq_rng = range(8) # [0,1,2,3,4]\n",
    "    \n",
    "    for i in pq_rng:\n",
    "        for j in pq_rng:\n",
    "            try:\n",
    "                tmp_mdl = ARMA(df, order=(i,j)).fit(\n",
    "                    method='mle', trend='nc'\n",
    "                )\n",
    "                tmp_aic = tmp_mdl.aic\n",
    "                if tmp_aic < best_aic:\n",
    "                    best_aic = tmp_aic\n",
    "                    best_order = (i, j)\n",
    "                    best_mdl = tmp_mdl\n",
    "            except: continue\n",
    "    print('aic: {:6.2f} | order: {}'.format(best_aic, best_order))                    \n",
    "    return best_aic, best_order, best_mdl\n",
    "\n",
    "def plot_corrs(n):\n",
    "    n = n # the time interval to partition the price series into\n",
    "    def func(i):\n",
    "        return (i - i%n)\n",
    "\n",
    "    df['ind'] = df.index\n",
    "    df['ind'] = df.ind.apply(func)\n",
    "    df['return_min'] = (df['close'])/(df['open'])\n",
    "    df['return_min'] = np.log(df['return_min'])\n",
    "    #df['return'] = (df['close']-df['open'].shift(periods = n-1))/(df['open'].shift(periods = m-1))\n",
    "    df1 = df.copy()\n",
    "    df1 = df.groupby(df.ind)\n",
    "    thres_up = 0.00\n",
    "    thres_down= 0.00\n",
    "    df1 = df1.apply(Get_indices)\n",
    "#     fig, axes = plt.subplots(2,2, figsize = (10,10))\n",
    "#     plot_acf(df1.Logreturn2, ax = axes[0,0])\n",
    "#     plot_acf(df1.Volatility, ax = axes[0,1])\n",
    "#     plot_pacf(df1.Logreturn2, ax = axes[1,0])\n",
    "#     plot_pacf(df1.Volatility, ax = axes[1,1])\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def fit_arma(df):\n",
    "    # find best order\n",
    "    # automatically fit the optimal ARIMA model for given time series\n",
    "    # train_len = int(train_test_split * len(df))\n",
    "    train_len = len(df)\n",
    "    arima_model_fitted = pmdarima.auto_arima(df[:train_len], start_p = 2, start_q = 2)\n",
    "    order = arima_model_fitted.get_params()['order']\n",
    "    # pmdarima.arima.ARIMA\n",
    "    # predict = arima_model_fitted.predict(n_periods = len(df)-train_len)\n",
    "    # res = df[train_len:] - predict\n",
    "    # plot_acf(res)\n",
    "    arima_residuals = arima_model_fitted.arima_res_.resid\n",
    "    # the following plots point to the best garch order\n",
    "    plot_acf(arima_residuals**2)\n",
    "    plot_pacf(arima_residuals**2)\n",
    "    return arima_model_fitted, order\n",
    "\n",
    "def fit_arma_garch(df, roll_window_len, order):\n",
    "    # df: log return series, roll_window_len: the time window to conduct ARMA-GARCH fitting on, order: order of GARCH\n",
    "    n_period = 1\n",
    "    T = roll_window_len\n",
    "    preds = []\n",
    "    for d in range(len(df)-T):\n",
    "        # fit ARMA on returns \n",
    "        best_aic, best_order, best_mdl = get_best_model(df[d:d+T])\n",
    "        #arima_model_fitted = pmdarima.auto_arima(df[d:d+T])\n",
    "        #p, d, q = arima_model_fitted.order\n",
    "        arima_residuals = best_mdl.resid\n",
    "\n",
    "        # fit a GARCH(order) model on the residuals of the ARMA model\n",
    "        garch = arch.arch_model(arima_residuals, p=order[0], q=order[1])\n",
    "        garch_fitted = garch.fit()\n",
    "\n",
    "        # Use ARMA to predict mu\n",
    "        predicted_mu = best_mdl.forecast()[0]\n",
    "        # Use GARCH to predict the residual\n",
    "        garch_forecast = garch_fitted.forecast(horizon=n_period)\n",
    "        predicted_et = garch_forecast.mean['h.1'].iloc[-1]\n",
    "        # # Combine both models' output: yt = mu + et\n",
    "        prediction = predicted_mu + predicted_et\n",
    "        preds.append(prediction)\n",
    "    \n",
    "    \n",
    "    return preds\n",
    "\n",
    "def do_everything(n, roll_window_len):\n",
    "    df1 = plot_corrs(n = n)\n",
    "    preds = fit_arma_garch(df1['Logreturn2'], roll_window_len = roll_window_len, order = (1,1))\n",
    "    T = np.arange(len(preds))\n",
    "    true_val = df1['Logreturn2'][-len(T):]\n",
    "    plt.plot(T, preds, label = 'prediction')\n",
    "    plt.plot(T, true_val, label = 'true value')\n",
    "    plt.title('prediction of return over period of ' + str(n) + ' mins')\n",
    "    plt.legend()\n",
    "    \n",
    "    pred_bool = [int(preds[i] > 0) for i in range(len(preds))]\n",
    "    true_bool = [int(list(true_val)[i] > 0) for i in range(len(preds))]\n",
    "    err = sum(abs(np.asarray(true_bool) - np.asarray(pred_bool)))/len(preds)\n",
    "    accuracy = 1 - err\n",
    "    return preds, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, accuracy = do_everything(n = 120, roll_window_len=444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
